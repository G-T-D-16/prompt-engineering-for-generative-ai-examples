{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "6pGV8uRvM2p5",
    "ExecuteTime": {
     "end_time": "2024-11-05T11:26:32.348518Z",
     "start_time": "2024-11-05T11:26:31.370662Z"
    }
   },
   "source": [
    "import re\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate\n",
    "import os"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gordontveito-duncan/Documents/GitHub/prompt-engineering-for-generative-ai-examples/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6yVUGK0oM2p7"
   },
   "source": [
    "# Objective: We are going to hand code a simple framework for the re-Act pattern.\n",
    "\n",
    "This focuses on using a language model to act as an agent, that can use several tools, and follows the following pattern:\n",
    "\n",
    "1. Observe the environment\n",
    "2. Interpret the environment with a thought\n",
    "3. Decide on an action\n",
    "4. Act on the environment\n",
    "5. Repeat steps 1 - 4 until we've find a solution or we've done too many iterations (the solution is \"i've found an answer\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EN5rr1bpM2p9"
   },
   "source": [
    "# How to extract the last action and action_input:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aI7GC0xmM2p9",
    "outputId": "bc1d843b-eaca-4f22-8fc0-b832d28e1914",
    "ExecuteTime": {
     "end_time": "2024-11-05T11:26:39.841884Z",
     "start_time": "2024-11-05T11:26:39.833844Z"
    }
   },
   "source": [
    "# Sample text\n",
    "text = \"\"\"\n",
    "Action: search_on_google\n",
    "Action_Input: Tom Hanks current wife\n",
    "\n",
    "action: search_on_wikipedia\n",
    "action_input: How old is Rita Wilson in 2023\n",
    "\n",
    "action : search_on_google\n",
    "action input: some other query\n",
    "\"\"\"\n",
    "\n",
    "# Compile regex patterns\n",
    "action_pattern = re.compile(r\"(?i)action\\s*:\\s*([^\\n]+)\", re.MULTILINE)\n",
    "action_input_pattern = re.compile(r\"(?i)action\\s*_*input\\s*:\\s*([^\\n]+)\", re.MULTILINE)\n",
    "\n",
    "# Find all occurrences of action and action_input\n",
    "actions = action_pattern.findall(text)\n",
    "action_inputs = action_input_pattern.findall(text)\n",
    "\n",
    "# Extract the last occurrence of action and action_input\n",
    "last_action = actions[-1] if actions else None\n",
    "last_action_input = action_inputs[-1] if action_inputs else None\n",
    "\n",
    "print(\"Last Action:\", last_action)\n",
    "print(\"Last Action Input:\", last_action_input)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Action: search_on_google\n",
      "Last Action Input: some other query\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MlyRYOf9M2p-"
   },
   "source": [
    "---\n",
    "\n",
    "`action_pattern = re.compile(r\"(?i)action\\s*:\\s*([^\\n]+)\", re.MULTILINE)`\n",
    "\n",
    "`(?i)`: This is called an inline flag and makes the regex pattern case-insensitive. It means that the pattern will match \"action\", \"Action\", \"ACTION\", or any other combination of uppercase and lowercase letters.\n",
    "\n",
    "`action`: This part of the pattern matches the word \"action\" literally. Due to the case-insensitive flag, it will match any capitalization of the word.\n",
    "\n",
    "`\\s*`: This part of the pattern matches zero or more whitespace characters (spaces, tabs, etc.). The \\* means \"zero or more\" and \\s is the regex shorthand for a whitespace character.\n",
    "\n",
    "`:`: This part of the pattern matches the colon character literally.\n",
    "\n",
    "`\\s*`: This is the same as the previous \\s\\* part, matching zero or more whitespace characters after the colon.\n",
    "\n",
    "`([^\\n]+)`: This part of the pattern is a capturing group, denoted by the parentheses. It matches one or more characters that are NOT a newline character. The ^ inside the square brackets [] negates the character class, and \\n represents the newline character. The + means \"one or more\". The text matched by this group will be extracted when using the findall() function.\n",
    "\n",
    "`re.MULTILINE`: This is a flag passed to re.compile() function. It tells the regex engine that the input text may have multiple lines, so the pattern should be applied line by line.\n",
    "\n",
    "In regular expressions, square brackets `[]` are used to define a character class, which is a set of characters that you want to match. For example, [abc] would match any single character that is either 'a', 'b', or 'c'.\n",
    "\n",
    "When you add a caret `(^)` at the beginning of the character class, it negates the character class, meaning it will match any character that is NOT in the character class. In other words, it inverts the set of characters you want to match.\n",
    "\n",
    "So, when we use `[^abc]`, it will match any single character that is NOT 'a', 'b', or 'c'. In the regex pattern `([^\\n]+)`, the character class is `[^n]`, which means it will match any character that is NOT a newline character (\\n). The + after the negated character class means that the pattern should match one or more characters that are not newlines.\n",
    "\n",
    "By using the negated character class `[^n]` in the capturing group, we ensure that the regex engine captures text up to the end of the line without including the newline character itself. This is useful when we want to extract the text after the word \"action\" or \"action input\" up to the end of the line.\n",
    "\n",
    "Overall, this regular expression pattern matches the word \"action\" (case-insensitive) followed by optional whitespace, a colon, optional whitespace again, and then captures any text up to the end of the line.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wyPVpVU9M2p_"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "quUwA9I9M2p_"
   },
   "source": [
    "`action_input_pattern = re.compile(r\"(?i)action_input\\s*:\\s*([^\\n]+)\", re.MULTILINE)`\n",
    "\n",
    "The two regular expressions are very similar, with the only difference being the literal text they match at the beginning of each pattern. I'll briefly describe each regex and highlight the difference:\n",
    "\n",
    "This pattern matches the word `\"action_input\"` (case-insensitive) followed by optional whitespace, a colon, optional whitespace again, and then captures any text up to the end of the line.\n",
    "\n",
    "The only difference between these two regex patterns is the literal text they are looking for at the beginning:\n",
    "\n",
    "action_pattern looks for the word `\"action\".`\n",
    "action_input_pattern looks for the word `\"action_input\".`\n",
    "Both patterns are case-insensitive, and they both capture the text following the matched word and the colon up to the end of the line. The purpose of these regex patterns is to extract the information after the keywords `\"action\"` and `\"action_input\"` from a given text.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KFuIeTQcM2p_"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fIjmSQNHM2p_",
    "ExecuteTime": {
     "end_time": "2024-11-05T11:27:25.156018Z",
     "start_time": "2024-11-05T11:27:25.141993Z"
    }
   },
   "source": [
    "def extract_last_action_and_input(text):\n",
    "    # Compile regex patterns\n",
    "    action_pattern = re.compile(r\"(?i)action\\s*:\\s*([^\\n]+)\", re.MULTILINE)\n",
    "    action_input_pattern = re.compile(\n",
    "        r\"(?i)action\\s*_*input\\s*:\\s*([^\\n]+)\", re.MULTILINE\n",
    "    )\n",
    "\n",
    "    # Find all occurrences of action and action_input\n",
    "    actions = action_pattern.findall(text)\n",
    "    action_inputs = action_input_pattern.findall(text)\n",
    "\n",
    "    # Extract the last occurrence of action and action_input\n",
    "    last_action = actions[-1] if actions else None\n",
    "    last_action_input = action_inputs[-1] if action_inputs else None\n",
    "\n",
    "    return {\"action\": last_action, \"action_input\": last_action_input}"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JKf2EnfCM2qA",
    "outputId": "4f5f486c-349e-4038-c933-c39998e895a9",
    "ExecuteTime": {
     "end_time": "2024-11-05T11:27:30.614892Z",
     "start_time": "2024-11-05T11:27:30.608885Z"
    }
   },
   "source": [
    "extract_last_action_and_input(text)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'action': 'search_on_google', 'action_input': 'some other query'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cLloPS3cM2qA"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SbZgabpGM2qA"
   },
   "source": [
    "Given that we will also need to find out whether the language model has found the final answer, we will use the following template:\n",
    "\n",
    "`\"I've found the answer: final_answer\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rmorxykzM2qA",
    "outputId": "900c8eba-dd1a-4088-abb9-685fd14ebbad",
    "ExecuteTime": {
     "end_time": "2024-11-05T11:27:42.290482Z",
     "start_time": "2024-11-05T11:27:42.282696Z"
    }
   },
   "source": [
    "final_answer_text = \"I've found the answer: final_answer\"\n",
    "\n",
    "# Write a regex to extract the final answer\n",
    "final_answer_pattern = re.compile(\n",
    "    r\"(?i)I've found the answer:\\s*([^\\n]+)\", re.MULTILINE\n",
    ")\n",
    "\n",
    "# Find all occurrences of the final answer\n",
    "final_answers = final_answer_pattern.findall(final_answer_text)\n",
    "print(\"Final Answers:\", final_answers)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answers: ['final_answer']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kDzET8StM2qA",
    "ExecuteTime": {
     "end_time": "2024-11-05T11:27:52.790708Z",
     "start_time": "2024-11-05T11:27:52.783205Z"
    }
   },
   "source": [
    "def extract_final_answer(text):\n",
    "    final_answer_pattern = re.compile(\n",
    "        r\"(?i)I've found the answer:\\s*([^\\n]+)\", re.MULTILINE\n",
    "    )\n",
    "    final_answers = final_answer_pattern.findall(text)\n",
    "    if final_answers:\n",
    "        return final_answers[0]\n",
    "    else:\n",
    "        return None"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jpVBxVzaM2qB",
    "outputId": "7c2c9974-5f5a-4725-fc09-449be1825921",
    "ExecuteTime": {
     "end_time": "2024-11-05T11:28:13.621403Z",
     "start_time": "2024-11-05T11:28:13.615835Z"
    }
   },
   "source": [
    "final_answer_text = \"I've found the answer: final_answer\"\n",
    "print(extract_final_answer(final_answer_text))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_answer\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "n9j_uGGgM2qB"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T11:30:45.898093Z",
     "start_time": "2024-11-05T11:30:45.873303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OPbIzfiUM2qB",
    "outputId": "43381fbf-e812-4e5a-c527-7123ababc628",
    "ExecuteTime": {
     "end_time": "2024-11-05T11:30:51.809546Z",
     "start_time": "2024-11-05T11:30:48.031054Z"
    }
   },
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_kwargs={\n",
    "        \"stop\": [\"tool_result:\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "tools = {}\n",
    "\n",
    "\n",
    "def search_on_google(query: str):\n",
    "    return f\"Jason Derulo doesn't have a wife or partner.\"\n",
    "\n",
    "\n",
    "tools[\"search_on_google\"] = {\n",
    "    \"function\": search_on_google,\n",
    "    \"description\": \"Searches on google for a query\",\n",
    "}\n",
    "\n",
    "\n",
    "base_prompt = \"\"\"\n",
    "You will attempt to solve the problem of finding the answer to a question.\n",
    "Use chain of thought reasoning to solve through the problem, using the following pattern:\n",
    "\n",
    "1. Observe the original question:\n",
    "original_question: original_problem_text\n",
    "2. Create an observation with the following pattern:\n",
    "observation: observation_text\n",
    "3. Create a thought based on the observation with the following pattern:\n",
    "thought: thought_text\n",
    "4. Use tools to act on the thought with the following pattern:\n",
    "action: tool_name\n",
    "action_input: tool_input\n",
    "\n",
    "Do not guess or assume the tool results. Instead, provide a structured output that includes the action and action_input.\n",
    "\n",
    "You have access to the following tools: {tools}.\n",
    "\n",
    "original_problem: {question}\n",
    "\"\"\"\n",
    "\n",
    "model_output = chat.invoke(\n",
    "    SystemMessagePromptTemplate.from_template(template=base_prompt).format_messages(\n",
    "        tools=tools, question=\"Is Jason Derulo with a partner?\"\n",
    "    )\n",
    ")\n",
    "print(model_output)\n",
    "\n",
    "\n",
    "# Extract the tool_name and tool_input from the model_output\n",
    "tool_name = extract_last_action_and_input(model_output.content)[\"action\"]\n",
    "tool_input = extract_last_action_and_input(model_output.content)[\"action_input\"]\n",
    "tool_result = tools[tool_name][\"function\"](tool_input)\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "----------\n",
    "The agent has opted to use the following tool:\n",
    "tool_name: {tool_name}\n",
    "tool_input: {tool_input}\n",
    "tool_result: {tool_result}\n",
    "----------\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "current_prompt = \"\"\"\n",
    "Based on the provided tool result:\n",
    "tool_result: {tool_result}\n",
    "\n",
    "Either provide the next observation, action, action_input, or the final answer if available.\n",
    "If you are providing the final answer, you must return the following pattern:\n",
    "\"I've found the answer: final_answer\" \"\"\"\n",
    "\n",
    "print(\"The second prompt shows\", current_prompt)\n",
    "\n",
    "model_output = chat(\n",
    "    SystemMessagePromptTemplate.from_template(template=current_prompt).format_messages(\n",
    "        tool_result=tool_result\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"----------\\n\\nThe model output is:\", model_output.content)\n",
    "# See if there is a final answer:\n",
    "final_answer = extract_final_answer(model_output.content)\n",
    "if final_answer:\n",
    "    print(f\"answer: {final_answer}\")\n",
    "else:\n",
    "    print(\"No final answer found.\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gordontveito-duncan/Documents/GitHub/prompt-engineering-for-generative-ai-examples/venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3490: UserWarning: Parameters {'stop'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"1. Observe the original question:\\noriginal_question: Is Jason Derulo with a partner?\\n\\n2. Create an observation:\\nobservation: Jason Derulo's relationship status is not always publicly known, so we might need to look up the latest information to find out if he is currently with a partner.\\n\\n3. Create a thought based on the observation:\\nthought: We can search online to find the most recent information about Jason Derulo's relationship status.\\n\\n4. Use a tool to act on the thought:\\naction: search_on_google\\naction_input: Jason Derulo current relationship status\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 116, 'prompt_tokens': 192, 'total_tokens': 308, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-492caf9c-d92c-4800-bcaa-89a1c4982d79-0' usage_metadata={'input_tokens': 192, 'output_tokens': 116, 'total_tokens': 308, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "\n",
      "----------\n",
      "The agent has opted to use the following tool:\n",
      "tool_name: search_on_google\n",
      "tool_input: Jason Derulo current relationship status\n",
      "tool_result: Jason Derulo doesn't have a wife or partner.\n",
      "----------\n",
      "\n",
      "The second prompt shows \n",
      "Based on the provided tool result:\n",
      "tool_result: {tool_result}\n",
      "\n",
      "Either provide the next observation, action, action_input, or the final answer if available.\n",
      "If you are providing the final answer, you must return the following pattern:\n",
      "\"I've found the answer: final_answer\" \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0k/3rxx7x4x7_7f028m32kgbqzh0000gn/T/ipykernel_68692/4196085321.py:78: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  model_output = chat(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\n",
      "The model output is: Do you want to know more information about Jason Derulo's personal life or career?\n",
      "No final answer found.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
