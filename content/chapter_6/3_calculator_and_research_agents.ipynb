{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:30:16.555774Z",
     "start_time": "2024-11-08T16:30:16.544432Z"
    }
   },
   "source": [
    "# Demonstrating how to use langchain.debug to print out the intermediate results with stack traces:\n",
    "import langchain\n",
    "langchain.debug = True"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:30:19.075221Z",
     "start_time": "2024-11-08T16:30:17.372535Z"
    }
   },
   "source": [
    "# Import necessary modules and functions from the langchain package:\n",
    "from langchain.chains import (\n",
    "    LLMMathChain,\n",
    ")\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent, Tool, AgentExecutor\n",
    "from langchain_openai.chat_models import ChatOpenAI"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gordontveito-duncan/Documents/GitHub/prompt-engineering-for-generative-ai-examples/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:08.291773Z",
     "start_time": "2024-11-08T16:31:08.270722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:09.921597Z",
     "start_time": "2024-11-08T16:31:09.134664Z"
    }
   },
   "source": [
    "# Initialize the ChatOpenAI with temperature set to 0:\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Create a LLMMathChain instance using the ChatOpenAI model:\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=model, verbose=True)\n",
    "\n",
    "# Download the prompt from the hub:\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run, # run the LLMMathChain\n",
    "        description=\"useful for when you need to answer questions about math\",\n",
    "        return_direct=True,\n",
    "    ),\n",
    "]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gordontveito-duncan/Documents/GitHub/prompt-engineering-for-generative-ai-examples/venv/lib/python3.9/site-packages/langsmith/client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:13.141020Z",
     "start_time": "2024-11-08T16:31:13.113079Z"
    }
   },
   "source": [
    "# Create an agent using the ChatOpenAI model and the tools:\n",
    "agent = create_openai_functions_agent(llm=model, tools=tools, prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:31:16.909534Z",
     "start_time": "2024-11-08T16:31:14.467929Z"
    }
   },
   "source": [
    "result = agent_executor.invoke({\"input\": \"W hat is 5 + 5?\"})\n",
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"W hat is 5 + 5?\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [9ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"input\": \"W hat is 5 + 5?\",\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"W hat is 5 + 5?\",\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful assistant\\nHuman: W hat is 5 + 5?\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [1.45s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"function_call\",\n",
      "          \"model_name\": \"gpt-3.5-turbo-0125\"\n",
      "        },\n",
      "        \"type\": \"ChatGenerationChunk\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessageChunk\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"arguments\": \"{\\\"__arg1\\\":\\\"5 + 5\\\"}\",\n",
      "                \"name\": \"Calculator\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"finish_reason\": \"function_call\",\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\"\n",
      "            },\n",
      "            \"type\": \"AIMessageChunk\",\n",
      "            \"id\": \"run-a50a5151-3694-47aa-bb5f-25e214585f6c\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence] [1.48s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[tool/start]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator] Entering Tool run with input:\n",
      "\u001B[0m\"5 + 5\"\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator > chain:LLMMathChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"question\": \"5 + 5\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator > chain:LLMMathChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"question\": \"5 + 5\",\n",
      "  \"stop\": [\n",
      "    \"```output\"\n",
      "  ]\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator > chain:LLMMathChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Translate a math problem into a expression that can be executed using Python's numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${Question with math problem.}\\n```text\\n${single line mathematical expression that solves the problem}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${Output of running the code}\\n```\\nAnswer: ${Answer}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\\\"37593 * 67\\\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\\\"37593**(1/5)\\\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: 5 + 5\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator > chain:LLMMathChain > chain:LLMChain > llm:ChatOpenAI] [945ms] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```text\\n5 + 5\\n```\\n...numexpr.evaluate(\\\"5 + 5\\\")...\\n\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```text\\n5 + 5\\n```\\n...numexpr.evaluate(\\\"5 + 5\\\")...\\n\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 21,\n",
      "                \"prompt_tokens\": 204,\n",
      "                \"total_tokens\": 225,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-1461d991-44fe-4222-a5e3-be32609b4449-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 204,\n",
      "              \"output_tokens\": 21,\n",
      "              \"total_tokens\": 225,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 21,\n",
      "      \"prompt_tokens\": 204,\n",
      "      \"total_tokens\": 225,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator > chain:LLMMathChain > chain:LLMChain] [946ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"```text\\n5 + 5\\n```\\n...numexpr.evaluate(\\\"5 + 5\\\")...\\n\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator > chain:LLMMathChain] [949ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"answer\": \"Answer: 10\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[tool/end]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator] [950ms] Exiting Tool run with output:\n",
      "\u001B[0m\"Answer: 10\"\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor] [2.43s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"Answer: 10\"\n",
      "}\n",
      "{'input': 'W hat is 5 + 5?', 'output': 'Answer: 10'}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Tool Usage:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:32:48.197724Z",
     "start_time": "2024-11-08T16:32:48.187174Z"
    }
   },
   "source": [
    "def google_search(query: str) -> str:\n",
    "    return \"James Phoenix is 31 years old.\"\n",
    "\n",
    "# List of tools that the agent can use.\n",
    "tools = [\n",
    "    Tool(\n",
    "        # The LLMMathChain tool for math calculations.\n",
    "        func=llm_math_chain.run,\n",
    "        name=\"Calculator\",\n",
    "        description=\"useful for when you need to answer questions about math\",\n",
    "    ),\n",
    "    Tool(\n",
    "        # Tool for counting characters in a string.\n",
    "        func=google_search,\n",
    "        name=\"google_search\",\n",
    "        description=\"useful for when you need to find out about someones age.\",\n",
    "    ),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:32:49.668606Z",
     "start_time": "2024-11-08T16:32:49.635846Z"
    }
   },
   "source": [
    "agent = create_openai_functions_agent(llm=model, tools=tools, prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T16:32:54.890755Z",
     "start_time": "2024-11-08T16:32:51.475917Z"
    }
   },
   "source": [
    "result = agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"\"\"Task: Google search for James Phoenix's age. \n",
    "        Then square it.\"\"\"}\n",
    ")\n",
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"Task: Google search for James Phoenix's age. \\n        Then square it.\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"input\": \"Task: Google search for James Phoenix's age. \\n        Then square it.\",\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"Task: Google search for James Phoenix's age. \\n        Then square it.\",\n",
      "  \"intermediate_steps\": [],\n",
      "  \"agent_scratchpad\": []\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful assistant\\nHuman: Task: Google search for James Phoenix's age. \\n        Then square it.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [1.09s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"function_call\",\n",
      "          \"model_name\": \"gpt-3.5-turbo-0125\"\n",
      "        },\n",
      "        \"type\": \"ChatGenerationChunk\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessageChunk\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"arguments\": \"{\\\"__arg1\\\":\\\"James Phoenix age\\\"}\",\n",
      "                \"name\": \"google_search\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"finish_reason\": \"function_call\",\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\"\n",
      "            },\n",
      "            \"type\": \"AIMessageChunk\",\n",
      "            \"id\": \"run-4bb2c15f-4df8-4cfe-b0f1-d6d661c556c3\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence] [1.09s] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[tool/start]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:google_search] Entering Tool run with input:\n",
      "\u001B[0m\"James Phoenix age\"\n",
      "\u001B[36;1m\u001B[1;3m[tool/end]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:google_search] [1ms] Exiting Tool run with output:\n",
      "\u001B[0m\"James Phoenix is 31 years old.\"\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful assistant\\nHuman: Task: Google search for James Phoenix's age. \\n        Then square it.\\nAI: {'arguments': '{\\\"__arg1\\\":\\\"James Phoenix age\\\"}', 'name': 'google_search'}\\nFunction: James Phoenix is 31 years old.\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [740ms] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"function_call\",\n",
      "          \"model_name\": \"gpt-3.5-turbo-0125\"\n",
      "        },\n",
      "        \"type\": \"ChatGenerationChunk\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessageChunk\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"arguments\": \"{\\\"__arg1\\\":\\\"31^2\\\"}\",\n",
      "                \"name\": \"Calculator\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"finish_reason\": \"function_call\",\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\"\n",
      "            },\n",
      "            \"type\": \"AIMessageChunk\",\n",
      "            \"id\": \"run-0b57db48-e1de-4e20-b359-6f145c3bca3e\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence] [747ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[tool/start]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator] Entering Tool run with input:\n",
      "\u001B[0m\"31^2\"\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator > chain:LLMMathChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"question\": \"31^2\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator > chain:LLMMathChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"question\": \"31^2\",\n",
      "  \"stop\": [\n",
      "    \"```output\"\n",
      "  ]\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator > chain:LLMMathChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Translate a math problem into a expression that can be executed using Python's numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${Question with math problem.}\\n```text\\n${single line mathematical expression that solves the problem}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${Output of running the code}\\n```\\nAnswer: ${Answer}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\\\"37593 * 67\\\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\\\"37593**(1/5)\\\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: 31^2\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator > chain:LLMMathChain > chain:LLMChain > llm:ChatOpenAI] [831ms] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```text\\n31**2\\n```\\n...numexpr.evaluate(\\\"31**2\\\")...\\n\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```text\\n31**2\\n```\\n...numexpr.evaluate(\\\"31**2\\\")...\\n\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 19,\n",
      "                \"prompt_tokens\": 203,\n",
      "                \"total_tokens\": 222,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-457d1aff-109f-4b12-977a-ac76e2f013cf-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 203,\n",
      "              \"output_tokens\": 19,\n",
      "              \"total_tokens\": 222,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 19,\n",
      "      \"prompt_tokens\": 203,\n",
      "      \"total_tokens\": 222,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator > chain:LLMMathChain > chain:LLMChain] [832ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"```text\\n31**2\\n```\\n...numexpr.evaluate(\\\"31**2\\\")...\\n\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator > chain:LLMMathChain] [837ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"answer\": \"Answer: 961\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[tool/end]\u001B[0m \u001B[1m[chain:AgentExecutor > tool:Calculator] [839ms] Exiting Tool run with output:\n",
      "\u001B[0m\"Answer: 961\"\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [1ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful assistant\\nHuman: Task: Google search for James Phoenix's age. \\n        Then square it.\\nAI: {'arguments': '{\\\"__arg1\\\":\\\"James Phoenix age\\\"}', 'name': 'google_search'}\\nFunction: James Phoenix is 31 years old.\\nAI: {'arguments': '{\\\"__arg1\\\":\\\"31^2\\\"}', 'name': 'Calculator'}\\nFunction: Answer: 961\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [721ms] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"James Phoenix is 31 years old. \\nThe square of 31 is 961.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"model_name\": \"gpt-3.5-turbo-0125\"\n",
      "        },\n",
      "        \"type\": \"ChatGenerationChunk\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessageChunk\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"James Phoenix is 31 years old. \\nThe square of 31 is 961.\",\n",
      "            \"response_metadata\": {\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\"\n",
      "            },\n",
      "            \"type\": \"AIMessageChunk\",\n",
      "            \"id\": \"run-50fbd07b-23be-4b45-b8ca-5b701f3ae468\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence > parser:OpenAIFunctionsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor > chain:RunnableSequence] [727ms] Exiting Chain run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[chain:AgentExecutor] [3.41s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"James Phoenix is 31 years old. \\nThe square of 31 is 961.\"\n",
      "}\n",
      "{'input': \"Task: Google search for James Phoenix's age. \\n        Then square it.\", 'output': 'James Phoenix is 31 years old. \\nThe square of 31 is 961.'}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
